{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"},{"sourceId":14353134,"sourceType":"datasetVersion","datasetId":9164893},{"sourceId":14353176,"sourceType":"datasetVersion","datasetId":9164919},{"sourceId":14353723,"sourceType":"datasetVersion","datasetId":9165315}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n\nsys.path.insert(\n    0,\n    \"/kaggle/input/csiro-timm-latest/pytorch-image-models-1.0.22\"\n)\n\nimport timm\nprint(\"version:\", timm.__version__)\nprint(\"file:\", timm.__file__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:28:05.223134Z","iopub.execute_input":"2025-12-31T11:28:05.223405Z","iopub.status.idle":"2025-12-31T11:28:10.175942Z","shell.execute_reply.started":"2025-12-31T11:28:05.223380Z","shell.execute_reply":"2025-12-31T11:28:10.175208Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"version: 1.0.22\nfile: /kaggle/input/csiro-timm-latest/pytorch-image-models-1.0.22/timm/__init__.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport timm\nfrom pytorch_lightning import LightningModule\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom sklearn.model_selection import KFold, GroupKFold, StratifiedGroupKFold\n\nfrom types import SimpleNamespace","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:28:10.177585Z","iopub.execute_input":"2025-12-31T11:28:10.178047Z","iopub.status.idle":"2025-12-31T11:28:44.973159Z","shell.execute_reply.started":"2025-12-31T11:28:10.178027Z","shell.execute_reply":"2025-12-31T11:28:44.971927Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"timm.list_models(\"*dino*\")[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:28:44.974472Z","iopub.execute_input":"2025-12-31T11:28:44.975281Z","iopub.status.idle":"2025-12-31T11:28:44.984255Z","shell.execute_reply.started":"2025-12-31T11:28:44.975241Z","shell.execute_reply":"2025-12-31T11:28:44.983231Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['vit_7b_patch16_dinov3',\n 'vit_base_patch14_dinov2',\n 'vit_base_patch14_reg4_dinov2',\n 'vit_base_patch16_dinov3',\n 'vit_base_patch16_dinov3_qkvb',\n 'vit_giant_patch14_dinov2',\n 'vit_giant_patch14_reg4_dinov2',\n 'vit_huge_plus_patch16_dinov3',\n 'vit_huge_plus_patch16_dinov3_qkvb',\n 'vit_large_patch14_dinov2']"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"DATA_ROOT = '/kaggle/input/csiro-biomass/'\n\n# train\ntrain_df = pd.read_csv(f'{DATA_ROOT}/train.csv')\ntrain_df[['sample_id_prefix', 'sample_id_suffix']] = train_df.sample_id.str.split('__', expand=True)\n\n# agg_train_df の作成\ncols = ['sample_id_prefix', 'image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm']\nagg_train_df = train_df.groupby(cols).apply(lambda df: df.set_index('target_name').target)\nagg_train_df.reset_index(inplace=True)\nagg_train_df.columns.name = None\n\nagg_train_df['image'] = agg_train_df.image_path.progress_apply(\n    lambda path: Image.open(DATA_ROOT + path).convert('RGB')\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:28:44.986321Z","iopub.execute_input":"2025-12-31T11:28:44.986611Z","iopub.status.idle":"2025-12-31T11:29:01.204617Z","shell.execute_reply.started":"2025-12-31T11:28:44.986592Z","shell.execute_reply":"2025-12-31T11:29:01.203782Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_173/2742864213.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  agg_train_df = train_df.groupby(cols).apply(lambda df: df.set_index('target_name').target)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/357 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d50d85a1cf843efadf923c2c9271a50"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 画像サイズ確認\nagg_train_df['image_size'] = agg_train_df.image.apply(lambda x: x.size)\nagg_train_df['image_size'].value_counts()\n\n# ターゲット合計確認\nnp.isclose(agg_train_df[['Dry_Green_g', 'Dry_Clover_g']].sum(axis=1),\n           agg_train_df['GDM_g'], atol=1e-4).mean()\n\nnp.isclose(agg_train_df[['GDM_g', 'Dry_Dead_g']].sum(axis=1),\n           agg_train_df['Dry_Total_g'], atol=1e-4).mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:29:01.206335Z","iopub.execute_input":"2025-12-31T11:29:01.207212Z","iopub.status.idle":"2025-12-31T11:29:01.217822Z","shell.execute_reply.started":"2025-12-31T11:29:01.207163Z","shell.execute_reply":"2025-12-31T11:29:01.217013Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0.9971988795518207"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# test.csv\ntest_df = pd.read_csv(DATA_ROOT + 'test.csv')\ntest_df[['sample_id_prefix', 'sample_id_suffix']] = test_df.sample_id.str.split('__', expand=True)\n\n# 推論用 agg_test_df\nagg_test_df = test_df.drop_duplicates(subset='sample_id_prefix').copy()\n\nagg_test_df['image'] = agg_test_df.image_path.progress_apply(\n    lambda path: Image.open(DATA_ROOT + path).convert('RGB')\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:29:01.218585Z","iopub.execute_input":"2025-12-31T11:29:01.218875Z","iopub.status.idle":"2025-12-31T11:29:01.295590Z","shell.execute_reply.started":"2025-12-31T11:29:01.218858Z","shell.execute_reply":"2025-12-31T11:29:01.294801Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f19fc14697468199a7368424f49b4e"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"class InferenceDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df.reset_index(drop=True)\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = self.df.iloc[idx][\"image\"]\n        width, height = image.size\n        mid_point = width // 2\n\n        # 左右に分割\n        left_image = image.crop((0, 0, mid_point, height))\n        right_image = image.crop((mid_point, 0, width, height))\n\n        if self.transforms:\n            left_image = self.transforms(image=np.array(left_image))[\"image\"]\n            right_image = self.transforms(image=np.array(right_image))[\"image\"]\n\n        return left_image, right_image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:11.372957Z","iopub.execute_input":"2025-12-31T11:33:11.373798Z","iopub.status.idle":"2025-12-31T11:33:11.379826Z","shell.execute_reply.started":"2025-12-31T11:33:11.373766Z","shell.execute_reply":"2025-12-31T11:33:11.378920Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"!ls /kaggle/input/model-dinov3-base/model.safetensors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:11.660235Z","iopub.execute_input":"2025-12-31T11:33:11.660783Z","iopub.status.idle":"2025-12-31T11:33:11.888771Z","shell.execute_reply.started":"2025-12-31T11:33:11.660760Z","shell.execute_reply":"2025-12-31T11:33:11.887991Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/model-dinov3-base/model.safetensors\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport timm\nfrom safetensors.torch import load_file\n\nclass TimmEncoder(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = timm.create_model(\n            cfg.model.backbone,\n            in_chans=cfg.task.slice_depth,\n            pretrained=False,\n            # drop_path_rate=cfg.model.drop_path_rate,\n            features_only=False,\n            num_classes=0,\n            global_pool=\"\",  # 自前でpoolingするのでここは空\n        )\n        state_dict = load_file(\"/kaggle/input/model-dinov3-base/model.safetensors\")\n        self.encoder.load_state_dict(state_dict)\n        self.dropout = nn.Dropout(cfg.model.dropout)\n\n        # 各ターゲット用ヘッド\n        def make_head():\n            return nn.Sequential(\n                nn.Linear(self.encoder.num_features * 2, 8),\n                nn.ReLU(inplace=True),\n                self.dropout,\n                nn.Linear(8, 1),\n            )\n\n        self.head_green = make_head()\n        self.head_clover = make_head()\n        self.head_dead = make_head()\n\n        self.softplus = nn.Softplus(beta=1.0)\n\n        if cfg.model.freeze_backbone:\n            for p in self.encoder.parameters():\n                p.requires_grad = False\n\n    def forward(self, left_img: torch.Tensor, right_img: torch.Tensor):\n        \"\"\"\n        左右画像をそれぞれ encoder に通して concat → 3ヘッド回帰\n        \"\"\"\n        # (B, C, H, W) -> (B, num_features)\n        left_feat = self.encoder.forward_features(left_img)  # (B, N, C) の場合もある\n        right_feat = self.encoder.forward_features(right_img)\n\n        # ViT系の場合、Global Poolingして (B, C) に\n        if left_feat.ndim == 3:\n            left_feat = left_feat.mean(dim=1)\n            right_feat = right_feat.mean(dim=1)\n\n        combined = torch.cat([left_feat, right_feat], dim=1)\n\n        green = self.softplus(self.head_green(combined))\n        clover = self.softplus(self.head_clover(combined))\n        dead = self.softplus(self.head_dead(combined))\n\n        out = torch.cat([green, clover, dead], dim=1)\n        return out\n\n    def set_grad_checkpointing(self, enable: bool = True):\n        self.encoder.set_grad_checkpointing(enable)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:11.890128Z","iopub.execute_input":"2025-12-31T11:33:11.890359Z","iopub.status.idle":"2025-12-31T11:33:11.900452Z","shell.execute_reply.started":"2025-12-31T11:33:11.890337Z","shell.execute_reply":"2025-12-31T11:33:11.899672Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def get_model_from_cfg(cfg):\n    if cfg.model.arch == \"timm_encoder\":\n        model = TimmEncoder(cfg)\n    else:\n        raise ValueError(f\"Unknown model architecture: {cfg.model.arch}\")\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:15.717622Z","iopub.execute_input":"2025-12-31T11:33:15.717930Z","iopub.status.idle":"2025-12-31T11:33:15.722476Z","shell.execute_reply.started":"2025-12-31T11:33:15.717908Z","shell.execute_reply":"2025-12-31T11:33:15.721797Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\ndef get_loss(cfg):\n    return MyLoss(cfg)\n\nclass MyLoss(nn.Module):\n    def __init__(self, cfg):\n        super(MyLoss, self).__init__()\n        self.cfg = cfg\n\n        # 基本は SmoothL1（元コードと同じ）\n        self.criterion = nn.SmoothL1Loss(reduction=\"mean\")\n\n        # 将来の拡張用（今は使わないが cfg で制御できる）\n        self.use_gdm = getattr(cfg.loss, \"use_gdm\", False)\n        self.use_total = getattr(cfg.loss, \"use_total\", False)\n\n    def forward(self, y_pred, y_true):\n        \"\"\"\n        Args:\n            y_pred (Tensor[float]): (batch_size, 3)\n                [Dry_Green_g, Dry_Clover_g, Dry_Dead_g]\n            y_true (Tensor[float]): (batch_size, 3)\n\n        Returns:\n            dict:\n                {\n                    \"loss\": total_loss,\n                    \"loss_reg\": regression_loss,\n                }\n        \"\"\"\n        return_dict = {}\n\n        # 形状チェック\n        assert y_pred.shape == y_true.shape, \\\n            f\"y_pred: {y_pred.shape}, y_true: {y_true.shape}\"\n\n        # --- 基本回帰損失 ---\n        loss_reg = self.criterion(y_pred, y_true)\n        loss_total = loss_reg\n\n        # --- 拡張例：GDM / Total を loss に含めたい場合 ---\n        if self.use_gdm:\n            # GDM = Green + Clover\n            gdm_pred = y_pred[:, 0] + y_pred[:, 1]\n            gdm_true = y_true[:, 0] + y_true[:, 1]\n            loss_gdm = self.criterion(gdm_pred, gdm_true)\n            loss_total = loss_total + loss_gdm\n            return_dict[\"loss_gdm\"] = loss_gdm\n\n        if self.use_total:\n            # Total = Green + Clover + Dead\n            total_pred = y_pred.sum(dim=1)\n            total_true = y_true.sum(dim=1)\n            loss_total_biomass = self.criterion(total_pred, total_true)\n            loss_total = loss_total + loss_total_biomass\n            return_dict[\"loss_total_biomass\"] = loss_total_biomass\n\n        return_dict[\"loss_reg\"] = loss_reg\n        return_dict[\"loss\"] = loss_total\n\n        return return_dict\n\n\ndef main():\n    pass\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:15.900567Z","iopub.execute_input":"2025-12-31T11:33:15.900815Z","iopub.status.idle":"2025-12-31T11:33:15.908324Z","shell.execute_reply.started":"2025-12-31T11:33:15.900798Z","shell.execute_reply":"2025-12-31T11:33:15.907589Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nfrom pytorch_lightning.core.module import LightningModule\nfrom timm.utils import ModelEmaV2\nfrom timm.optim import create_optimizer_v2\nfrom timm.scheduler import create_scheduler_v2\nimport torch\n\nfrom timm.utils import ModelEmaV3\n\n\n\nclass MyModel(LightningModule):\n    def __init__(self, cfg, mode=\"train\"):\n        super().__init__()\n        self.preds = None\n        self.gts = None\n\n        self.cfg = cfg\n        self.mode = mode\n        \n        self.model = get_model_from_cfg(cfg)\n\n        # epoch 集計用\n        self.val_outputs = []\n        self.val_targets = []\n\n        if mode != \"test\" and cfg.model.ema:\n            self.model_ema = ModelEmaV3(\n                self.model,\n                decay=cfg.model.ema_decay,\n                update_after_step=cfg.model.ema_update_after_step,\n            )\n\n        self.loss = get_loss(cfg)\n\n\n    def forward(self, left_img, right_img):\n        return self.model(left_img, right_img)\n\n    def training_step(self, batch, batch_idx):\n        left_img, right_img, targets = batch  # (B, 3)\n        targets = targets.float()\n\n        outputs = self(left_img, right_img)\n        loss_dict = self.loss(outputs, targets)\n\n        self.log_dict(\n            loss_dict,\n            on_step=False,\n            on_epoch=True,\n            prog_bar=True,\n            sync_dist=True,\n        )\n        return loss_dict[\"loss\"]\n\n    def on_train_batch_end(self, out, batch, batch_idx):\n        if self.cfg.model.ema:\n            self.model_ema.update(self.model)\n\n    def validation_step(self, batch, batch_idx):\n        left_img, right_img, targets = batch\n        targets = targets.float()\n\n        outputs = self(left_img, right_img)\n        loss_dict = self.loss(outputs, targets)\n\n        self.log(\"val_loss\", loss_dict[\"loss\"], prog_bar=True, sync_dist=True)\n        \n        self.val_outputs.append(outputs.detach())\n        self.val_targets.append(targets.detach())\n\n        return loss_dict\n\n    def on_validation_epoch_end(self):\n        outputs = torch.cat(self.val_outputs).cpu().numpy()\n        targets = torch.cat(self.val_targets).cpu().numpy()\n\n        weighted_r2, r2_scores = calc_metric(outputs, targets)\n\n        # メトリクスをログ\n        self.log(\"val_weighted_r2\", weighted_r2, prog_bar=True)\n\n        # 複数ターゲットなら個別ログも可\n        for i, r2 in enumerate(r2_scores):\n            self.log(f\"val_r2_target_{i}\", r2)\n\n        # 次epochに向けてクリア\n        self.val_outputs.clear()\n        self.val_targets.clear()\n\n        # 複数ターゲットなら個別ログも可\n        for i, r2 in enumerate(r2_scores):\n            self.log(f\"val_r2_target_{i}\", r2)\n\n        # 次epochに向けてクリア\n        self.val_outputs.clear()\n        self.val_targets.clear()\n\n    def configure_optimizers(self):\n        optimizer = create_optimizer_v2(model_or_params=self.model, **self.cfg.opt)\n\n        scheduler, _ = create_scheduler_v2(\n            optimizer=optimizer,\n            num_epochs=self.cfg.trainer.max_epochs,\n            **self.cfg.scheduler\n        )\n\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"epoch\",\n                \"monitor\": \"val_weighted_r2\",\n            },\n        }\n\n    def lr_scheduler_step(self, scheduler, metric):\n        scheduler.step(epoch=self.current_epoch)\n    #     # scheduler.step_update(num_updates=self.global_step)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:16.108091Z","iopub.execute_input":"2025-12-31T11:33:16.108801Z","iopub.status.idle":"2025-12-31T11:33:16.121433Z","shell.execute_reply.started":"2025-12-31T11:33:16.108775Z","shell.execute_reply":"2025-12-31T11:33:16.120595Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from types import SimpleNamespace\n\ncfg = SimpleNamespace()\n\n# --- task ---\ncfg.task = SimpleNamespace(\n    img_size=224,\n    img_depth=16,\n    fixed_depth=16,\n    slice_depth=3,\n    pretrain=False,\n    dirname=\"train_npzs\"\n)\n\n# --- model ---\ncfg.model = SimpleNamespace(\n    freeze_end_epoch=0,\n    arch=\"timm_encoder\",\n    in_channels=16,\n    out_channels=1,\n    depth=4,\n    base_filters=64,\n    dropout=0.1,\n    use_batchnorm=True,\n    activation=\"relu\",\n    swa=False,\n    freeze_backbone=False,\n    backbone=\"vit_base_patch16_dinov3_qkvb\",\n    ema=False,\n    resume_path=None,\n    drop_path_rate=0.0,\n    img_size=128,\n    img_depth=16,\n    kernel_size=5,\n    class_num=5\n)\n\n# --- data ---\ncfg.data = SimpleNamespace(\n    fold_num=5,\n    fold_id=0,\n    num_workers=8,\n    batch_size=32,\n    train_all=False,\n    input_dir=None,\n    output_dir=None,\n    val_output_dir=None\n)\n\n# --- trainer ---\ncfg.trainer = SimpleNamespace(\n    max_epochs=30,\n    devices=\"auto\",\n    strategy=\"auto\",\n    check_val_every_n_epoch=5,\n    sync_batchnorm=False,\n    accelerator=\"gpu\",\n    precision=32,\n    gradient_clip_val=None,\n    accumulate_grad_batches=1,\n    deterministic=True\n)\n\n# --- test ---\ncfg.test = SimpleNamespace(\n    mode=\"test\",\n    output_dir=\"preds_results\"\n)\n\n# --- opt ---\ncfg.opt = SimpleNamespace(\n    opt=\"AdamW\",\n    lr=1e-3,\n    weight_decay=0.01\n)\n\n# --- scheduler ---\ncfg.scheduler = SimpleNamespace(\n    sched=\"cosine\",\n    min_lr=0.0,\n    warmup_epochs=0\n)\n\n# --- loss ---\ncfg.loss = SimpleNamespace(\n    mixup=0.0,\n    cutmix=0.0\n)\n\n# --- wandb ---\ncfg.wandb = SimpleNamespace(\n    project=\"csiro2025\",\n    name=\"exp_0\",\n    fast_dev_run=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:16.289075Z","iopub.execute_input":"2025-12-31T11:33:16.289701Z","iopub.status.idle":"2025-12-31T11:33:16.296806Z","shell.execute_reply.started":"2025-12-31T11:33:16.289677Z","shell.execute_reply":"2025-12-31T11:33:16.296063Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"!ls /kaggle/input/csiro-simple-exp5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:16.347390Z","iopub.execute_input":"2025-12-31T11:33:16.347641Z","iopub.status.idle":"2025-12-31T11:33:16.573500Z","shell.execute_reply.started":"2025-12-31T11:33:16.347622Z","shell.execute_reply":"2025-12-31T11:33:16.572736Z"}},"outputs":[{"name":"stdout","text":"exp_5_epoch029_val_loss8.5536.ckpt\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"def get_val_transforms(cfg):\n    return A.Compose(\n        [\n            A.Resize(height=cfg.task.img_size, width=cfg.task.img_size, p=1),\n            # A.RandomScale(scale_limit=(1.0, 1.0), p=1),\n            # A.PadIfNeeded(min_height=cfg.task.img_size, min_width=cfg.task.img_size, p=1.0,\n            #              border_mode=cv2.BORDER_CONSTANT, value=0),\n            # A.Crop(y_max=self.cfg.data.val_img_h, x_max=self.cfg.data.val_img_w, p=1.0),\n            A.Normalize(p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n            ToTensorV2(p=1.0),\n        ],\n        p=1.0,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:37:01.904893Z","iopub.execute_input":"2025-12-31T11:37:01.905242Z","iopub.status.idle":"2025-12-31T11:37:01.910812Z","shell.execute_reply.started":"2025-12-31T11:37:01.905196Z","shell.execute_reply":"2025-12-31T11:37:01.909979Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nckpt_path = \"/kaggle/input/csiro-simple-exp5/exp_5_epoch029_val_loss8.5536.ckpt\"\n\nmodel = MyModel.load_from_checkpoint(ckpt_path, cfg=cfg, mode=\"test\")\nmodel.to(device)\nmodel.eval()\n\ntest_dataset = InferenceDataset(agg_test_df, get_val_transforms(cfg))\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n\ndef predict(model, dataloader, device):\n    model.to(device)\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for left_img, right_img in dataloader:\n            left_img = left_img.to(device)\n            right_img = right_img.to(device)\n            outputs = model(left_img, right_img)\n            preds.append(outputs.cpu())\n    return torch.cat(preds).numpy()\n\n\npreds = predict(model, test_loader, device)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:37:03.762605Z","iopub.execute_input":"2025-12-31T11:37:03.763174Z","iopub.status.idle":"2025-12-31T11:37:05.890405Z","shell.execute_reply.started":"2025-12-31T11:37:03.763151Z","shell.execute_reply":"2025-12-31T11:37:05.889415Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"agg_test_df[['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g']] = preds\nagg_test_df['GDM_g'] = agg_test_df.Dry_Green_g + agg_test_df.Dry_Clover_g\nagg_test_df['Dry_Total_g'] = agg_test_df.GDM_g + agg_test_df.Dry_Dead_g\n\ncols = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\nsub_df = agg_test_df.set_index('sample_id_prefix')[cols].stack().reset_index()\nsub_df.columns = ['sample_id_prefix', 'target_name', 'target']\nsub_df['sample_id'] = sub_df.sample_id_prefix + '__' + sub_df.target_name\n\nsub_df[['sample_id', 'target']].to_csv('submission.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:37:05.892130Z","iopub.execute_input":"2025-12-31T11:37:05.892596Z","iopub.status.idle":"2025-12-31T11:37:05.906930Z","shell.execute_reply.started":"2025-12-31T11:37:05.892553Z","shell.execute_reply":"2025-12-31T11:37:05.906025Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"sub_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:37:05.907767Z","iopub.execute_input":"2025-12-31T11:37:05.908486Z","iopub.status.idle":"2025-12-31T11:37:05.924343Z","shell.execute_reply.started":"2025-12-31T11:37:05.908467Z","shell.execute_reply":"2025-12-31T11:37:05.923739Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"  sample_id_prefix   target_name     target                   sample_id\n0     ID1001187975  Dry_Clover_g   0.007295  ID1001187975__Dry_Clover_g\n1     ID1001187975    Dry_Dead_g  14.745153    ID1001187975__Dry_Dead_g\n2     ID1001187975   Dry_Green_g  28.728642   ID1001187975__Dry_Green_g\n3     ID1001187975   Dry_Total_g  43.481091   ID1001187975__Dry_Total_g\n4     ID1001187975         GDM_g  28.735937         ID1001187975__GDM_g","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id_prefix</th>\n      <th>target_name</th>\n      <th>target</th>\n      <th>sample_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID1001187975</td>\n      <td>Dry_Clover_g</td>\n      <td>0.007295</td>\n      <td>ID1001187975__Dry_Clover_g</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID1001187975</td>\n      <td>Dry_Dead_g</td>\n      <td>14.745153</td>\n      <td>ID1001187975__Dry_Dead_g</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID1001187975</td>\n      <td>Dry_Green_g</td>\n      <td>28.728642</td>\n      <td>ID1001187975__Dry_Green_g</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID1001187975</td>\n      <td>Dry_Total_g</td>\n      <td>43.481091</td>\n      <td>ID1001187975__Dry_Total_g</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID1001187975</td>\n      <td>GDM_g</td>\n      <td>28.735937</td>\n      <td>ID1001187975__GDM_g</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"!head submission.csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T11:33:20.874855Z","iopub.execute_input":"2025-12-31T11:33:20.875275Z","iopub.status.idle":"2025-12-31T11:33:21.109378Z","shell.execute_reply.started":"2025-12-31T11:33:20.875247Z","shell.execute_reply":"2025-12-31T11:33:21.108684Z"}},"outputs":[{"name":"stdout","text":"sample_id,target\nID1001187975__Dry_Clover_g,0.007294931\nID1001187975__Dry_Dead_g,14.745153\nID1001187975__Dry_Green_g,28.728642\nID1001187975__Dry_Total_g,43.48109\nID1001187975__GDM_g,28.735937\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}